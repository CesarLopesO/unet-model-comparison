{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T15:23:28.799188Z",
     "start_time": "2025-03-18T15:23:28.794514Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "\n",
    "DATASET_DIR = \"../datasets\"\n",
    "IMAGE_DIR_TRAIN = os.path.join(DATASET_DIR, \"image\", \"train\")\n",
    "MASK_DIR_TRAIN = os.path.join(DATASET_DIR, \"mask\", \"train\")\n",
    "IMAGE_DIR_VAL = os.path.join(DATASET_DIR, \"image\", \"validation\")\n",
    "MASK_DIR_VAL = os.path.join(DATASET_DIR, \"mask\", \"validation\")\n",
    "#SUBINDO UM NIVEL NOS CAMINHOOS"
   ],
   "id": "90173420f19b83a3",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T15:23:30.513213Z",
     "start_time": "2025-03-18T15:23:28.861552Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Bloco 2: DefiniÃ§Ã£o do Modelo U-Net++\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Bloco de ConvoluÃ§Ã£o usado no Encoder e Decoder\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "# Arquitetura U-Net++\n",
    "class UNetPlusPlus(nn.Module):\n",
    "    def __init__(self, num_classes=1, input_channels=3, deep_supervision=False):\n",
    "        super(UNetPlusPlus, self).__init__()\n",
    "        self.deep_supervision = deep_supervision\n",
    "\n",
    "        # Encoder\n",
    "        self.conv0_0 = ConvBlock(input_channels, 64)\n",
    "        self.conv1_0 = ConvBlock(64, 128)\n",
    "        self.conv2_0 = ConvBlock(128, 256)\n",
    "        self.conv3_0 = ConvBlock(256, 512)\n",
    "        self.conv4_0 = ConvBlock(512, 1024)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Decoder com densa conexÃ£o\n",
    "        self.conv0_1 = ConvBlock(64 + 128, 64)\n",
    "        self.conv0_2 = ConvBlock(64*2 + 128, 64)\n",
    "        self.conv0_3 = ConvBlock(64*3 + 128, 64)\n",
    "        self.conv0_4 = ConvBlock(64*4 + 128, 64)\n",
    "\n",
    "        self.conv1_1 = ConvBlock(128 + 256, 128)\n",
    "        self.conv1_2 = ConvBlock(128*2 + 256, 128)\n",
    "        self.conv1_3 = ConvBlock(128*3 + 256, 128)\n",
    "\n",
    "        self.conv2_1 = ConvBlock(256 + 512, 256)\n",
    "        self.conv2_2 = ConvBlock(256*2 + 512, 256)\n",
    "\n",
    "        self.conv3_1 = ConvBlock(512 + 1024, 512)\n",
    "\n",
    "        self.upsample = lambda x, target: F.interpolate(x, size=target.shape[2:], mode='bilinear', align_corners=True)\n",
    "\n",
    "        # SaÃ­das\n",
    "        self.final_1 = nn.Conv2d(64, num_classes, kernel_size=1)\n",
    "        self.final_2 = nn.Conv2d(64, num_classes, kernel_size=1)\n",
    "        self.final_3 = nn.Conv2d(64, num_classes, kernel_size=1)\n",
    "        self.final_4 = nn.Conv2d(64, num_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0_0 = self.conv0_0(x)\n",
    "        x1_0 = self.conv1_0(self.pool(x0_0))\n",
    "        x2_0 = self.conv2_0(self.pool(x1_0))\n",
    "        x3_0 = self.conv3_0(self.pool(x2_0))\n",
    "        x4_0 = self.conv4_0(self.pool(x3_0))\n",
    "\n",
    "        x0_1 = self.conv0_1(torch.cat([x0_0, self.upsample(x1_0, x0_0)], 1))\n",
    "        x1_1 = self.conv1_1(torch.cat([x1_0, self.upsample(x2_0, x1_0)], 1))\n",
    "        x2_1 = self.conv2_1(torch.cat([x2_0, self.upsample(x3_0, x2_0)], 1))\n",
    "        x3_1 = self.conv3_1(torch.cat([x3_0, self.upsample(x4_0, x3_0)], 1))\n",
    "\n",
    "        x0_2 = self.conv0_2(torch.cat([x0_0, x0_1, self.upsample(x1_1, x0_0)], 1))\n",
    "        x1_2 = self.conv1_2(torch.cat([x1_0, x1_1, self.upsample(x2_1, x1_0)], 1))\n",
    "        x2_2 = self.conv2_2(torch.cat([x2_0, x2_1, self.upsample(x3_1, x2_0)], 1))\n",
    "\n",
    "        x0_3 = self.conv0_3(torch.cat([x0_0, x0_1, x0_2, self.upsample(x1_2, x0_0)], 1))\n",
    "        x1_3 = self.conv1_3(torch.cat([x1_0, x1_1, x1_2, self.upsample(x2_2, x1_0)], 1))\n",
    "\n",
    "        x0_4 = self.conv0_4(torch.cat([x0_0, x0_1, x0_2, x0_3, self.upsample(x1_3, x0_0)], 1))\n",
    "\n",
    "        if self.deep_supervision:\n",
    "            output1 = self.final_1(x0_1)\n",
    "            output2 = self.final_2(x0_2)\n",
    "            output3 = self.final_3(x0_3)\n",
    "            output4 = self.final_4(x0_4)\n",
    "            return [output1, output2, output3, output4]\n",
    "        else:\n",
    "            output = self.final_4(x0_4)\n",
    "            return output\n",
    "\n",
    "# Instanciando o modelo\n",
    "num_classes = 1\n",
    "model = UNetPlusPlus(num_classes=num_classes)\n",
    "\n",
    "# Imprimindo a arquitetura do modelo\n",
    "print(model)\n"
   ],
   "id": "8387316a6db39c55",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNetPlusPlus(\n",
      "  (conv0_0): ConvBlock(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (conv1_0): ConvBlock(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (conv2_0): ConvBlock(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (conv3_0): ConvBlock(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (conv4_0): ConvBlock(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv0_1): ConvBlock(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (conv0_2): ConvBlock(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (conv0_3): ConvBlock(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(320, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (conv0_4): ConvBlock(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(384, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (conv1_1): ConvBlock(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (conv1_2): ConvBlock(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (conv1_3): ConvBlock(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(640, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (conv2_1): ConvBlock(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (conv2_2): ConvBlock(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (conv3_1): ConvBlock(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(1536, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (final_1): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (final_2): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (final_3): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (final_4): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T15:23:30.950138Z",
     "start_time": "2025-03-18T15:23:30.598482Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Bloco Extra: ConfiguraÃ§Ã£o do DataLoader (Igual ao U-Net Normal)\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "# DefiniÃ§Ã£o do dataset customizado\n",
    "class ISICDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.image_list = sorted(os.listdir(image_dir))\n",
    "        self.mask_list = sorted(os.listdir(mask_dir))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx >= len(self.image_list):\n",
    "            idx = len(self.image_list) - 1  # Garante que nÃ£o acessa um Ã­ndice inexistente\n",
    "\n",
    "        img_path = os.path.join(self.image_dir, self.image_list[idx])\n",
    "        mask_path = os.path.join(self.mask_dir, self.mask_list[idx])\n",
    "\n",
    "        image = cv2.imread(img_path)\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        if image is None or mask is None:\n",
    "            print(f\"âš ï¸ Imagem ou MÃ¡scara corrompida em: {img_path} ou {mask_path}\")\n",
    "            return self.__getitem__((idx + 1) % len(self.image_list))\n",
    "\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image, (256, 256))\n",
    "        mask = cv2.resize(mask, (256, 256))\n",
    "\n",
    "        image = image / 255.0\n",
    "        mask = (mask > 0).astype(np.float32)\n",
    "\n",
    "        image = torch.tensor(image, dtype=torch.float32).permute(2, 0, 1)\n",
    "        mask = torch.tensor(mask, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "\n",
    "# Caminho dos datasets (relativo ao notebook)\n",
    "DATASET_DIR = \"../datasets\"\n",
    "IMAGE_DIR_TRAIN = os.path.join(DATASET_DIR, \"image\", \"train\")\n",
    "MASK_DIR_TRAIN = os.path.join(DATASET_DIR, \"mask\", \"train\")\n",
    "IMAGE_DIR_VAL = os.path.join(DATASET_DIR, \"image\", \"validation\")\n",
    "MASK_DIR_VAL = os.path.join(DATASET_DIR, \"mask\", \"validation\")\n",
    "\n",
    "# Criar dataset e DataLoader\n",
    "train_dataset = ISICDataset(IMAGE_DIR_TRAIN, MASK_DIR_TRAIN)\n",
    "val_dataset = ISICDataset(IMAGE_DIR_VAL, MASK_DIR_VAL)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, drop_last=True)\n",
    "\n",
    "# Teste: Exibir um batch do DataLoader\n",
    "batch = next(iter(train_loader))\n",
    "images, masks = batch\n",
    "\n",
    "print(f\"Formato do batch de imagens: {images.shape}\")  # Esperado: [8, 3, 256, 256]\n",
    "print(f\"Formato do batch de mÃ¡scaras: {masks.shape}\")  # Esperado: [8, 1, 256, 256]\n"
   ],
   "id": "d73b7886c97af518",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formato do batch de imagens: torch.Size([8, 3, 256, 256])\n",
      "Formato do batch de mÃ¡scaras: torch.Size([8, 1, 256, 256])\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T15:23:33.490948Z",
     "start_time": "2025-03-18T15:23:32.550424Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Bloco 4: FunÃ§Ãµes de Perda e MÃ©tricas (Igual ao U-Net Normal)\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "# ConfiguraÃ§Ã£o do dispositivo (usando CPU)\n",
    "device = torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# FunÃ§Ã£o de perda (Binary Cross Entropy com Dice Loss)\n",
    "def dice_loss(pred, target, smooth=1e-5):\n",
    "    pred = torch.sigmoid(pred)  # Converte logits para probabilidade\n",
    "    intersection = (pred * target).sum()\n",
    "    return 1 - ((2. * intersection + smooth) / (pred.sum() + target.sum() + smooth))\n",
    "\n",
    "criterion = lambda pred, target: 0.5 * F.binary_cross_entropy_with_logits(pred, target) + 0.5 * dice_loss(pred, target)\n",
    "\n",
    "# Otimizador\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# FunÃ§Ãµes para mÃ©tricas\n",
    "def iou(pred, target, threshold=0.5):\n",
    "    pred = (torch.sigmoid(pred) > threshold).float()\n",
    "    intersection = (pred * target).sum()\n",
    "    union = pred.sum() + target.sum() - intersection\n",
    "    return (intersection + 1e-5) / (union + 1e-5)\n",
    "\n",
    "def dice_coefficient(pred, target, threshold=0.5):\n",
    "    pred = (torch.sigmoid(pred) > threshold).float()\n",
    "    intersection = (pred * target).sum()\n",
    "    return (2. * intersection + 1e-5) / (pred.sum() + target.sum() + 1e-5)\n",
    "\n",
    "def precision(pred, target, threshold=0.5):\n",
    "    pred = (torch.sigmoid(pred) > threshold).float()\n",
    "    true_positive = (pred * target).sum()\n",
    "    predicted_positive = pred.sum()\n",
    "    return (true_positive + 1e-5) / (predicted_positive + 1e-5)\n",
    "\n",
    "def recall(pred, target, threshold=0.5):\n",
    "    pred = (torch.sigmoid(pred) > threshold).float()\n",
    "    true_positive = (pred * target).sum()\n",
    "    actual_positive = target.sum()\n",
    "    return (true_positive + 1e-5) / (actual_positive + 1e-5)\n",
    "\n",
    "def f1_score(pred, target, threshold=0.5):\n",
    "    p = precision(pred, target, threshold)\n",
    "    r = recall(pred, target, threshold)\n",
    "    return 2 * (p * r) / (p + r + 1e-5)\n"
   ],
   "id": "b406dd4884aab3ac",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d56988cd57800d75"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T15:24:44.370255Z",
     "start_time": "2025-03-18T15:23:37.148619Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Bloco 5: FunÃ§Ã£o de Treinamento e ValidaÃ§Ã£o (Igual ao U-Net Normal)\n",
    "\n",
    "import torch\n",
    "import time\n",
    "\n",
    "# ConfiguraÃ§Ã£o do dispositivo (usando CPU)\n",
    "device = torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# FunÃ§Ã£o para treinar o modelo com mÃ©tricas\n",
    "def train_model(model, train_loader, val_loader, epochs=10):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        start_time = time.time()\n",
    "\n",
    "        # MÃ©tricas de treino\n",
    "        train_iou, train_dice, train_precision, train_recall, train_f1 = 0, 0, 0, 0, 0\n",
    "\n",
    "        for images, masks in train_loader:\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "            # Forward\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "\n",
    "            # Backward\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            # Calcular mÃ©tricas para o batch\n",
    "            train_iou += iou(outputs, masks).item()\n",
    "            train_dice += dice_coefficient(outputs, masks).item()\n",
    "            train_precision += precision(outputs, masks).item()\n",
    "            train_recall += recall(outputs, masks).item()\n",
    "            train_f1 += f1_score(outputs, masks).item()\n",
    "\n",
    "        # ValidaÃ§Ã£o\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_iou, val_dice, val_precision, val_recall, val_f1 = 0, 0, 0, 0, 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, masks in val_loader:\n",
    "                images, masks = images.to(device), masks.to(device)\n",
    "                outputs = model(images)\n",
    "                val_loss += criterion(outputs, masks).item()\n",
    "\n",
    "                # Calcular mÃ©tricas para o batch\n",
    "                val_iou += iou(outputs, masks).item()\n",
    "                val_dice += dice_coefficient(outputs, masks).item()\n",
    "                val_precision += precision(outputs, masks).item()\n",
    "                val_recall += recall(outputs, masks).item()\n",
    "                val_f1 += f1_score(outputs, masks).item()\n",
    "\n",
    "        # Exibir progresso\n",
    "        print(f\"ðŸ“Œ Ã‰poca [{epoch+1}/{epochs}] - Loss Treino: {epoch_loss/len(train_loader):.4f} | Loss ValidaÃ§Ã£o: {val_loss/len(val_loader):.4f}\")\n",
    "        print(f\"   MÃ©tricas de Treino -> IoU: {train_iou/len(train_loader):.4f} | Dice: {train_dice/len(train_loader):.4f} | Prec: {train_precision/len(train_loader):.4f} | Rec: {train_recall/len(train_loader):.4f} | F1: {train_f1/len(train_loader):.4f}\")\n",
    "        print(f\"   MÃ©tricas de ValidaÃ§Ã£o -> IoU: {val_iou/len(val_loader):.4f} | Dice: {val_dice/len(val_loader):.4f} | Prec: {val_precision/len(val_loader):.4f} | Rec: {val_recall/len(val_loader):.4f} | F1: {val_f1/len(val_loader):.4f}\")\n",
    "        print(f\"   Tempo da Ã‰poca: {time.time() - start_time:.2f}s\")\n",
    "\n",
    "# Treinar o modelo com mÃ©tricas\n",
    "train_model(model, train_loader, val_loader, epochs=100)\n"
   ],
   "id": "23985119a895ce83",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 66\u001B[0m\n\u001B[1;32m     63\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m   Tempo da Ã‰poca: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtime\u001B[38;5;241m.\u001B[39mtime()\u001B[38;5;250m \u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;250m \u001B[39mstart_time\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.2f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124ms\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     65\u001B[0m \u001B[38;5;66;03m# Treinar o modelo com mÃ©tricas\u001B[39;00m\n\u001B[0;32m---> 66\u001B[0m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[5], line 29\u001B[0m, in \u001B[0;36mtrain_model\u001B[0;34m(model, train_loader, val_loader, epochs)\u001B[0m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;66;03m# Backward\u001B[39;00m\n\u001B[1;32m     28\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m---> 29\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     30\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m     32\u001B[0m epoch_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem()\n",
      "File \u001B[0;32m~/Pycharm/variacoes_unet/.venv/lib/python3.11/site-packages/torch/_tensor.py:626\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    616\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    617\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    618\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    619\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    624\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    625\u001B[0m     )\n\u001B[0;32m--> 626\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    627\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    628\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Pycharm/variacoes_unet/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py:347\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    342\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    344\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[1;32m    345\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    346\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 347\u001B[0m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    348\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    349\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    350\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    351\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    352\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    353\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    354\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    355\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Pycharm/variacoes_unet/.venv/lib/python3.11/site-packages/torch/autograd/graph.py:823\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[0;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[1;32m    821\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[1;32m    822\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 823\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    824\u001B[0m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    825\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[1;32m    826\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    827\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
